{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t-kgatmiry/miniconda3/envs/env3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Mymodel definition\n",
    "from transformers import GPT2Model, GPT2LMHeadModel, GPT2Config, PreTrainedModel\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "\n",
    "class MyModel(PreTrainedModel):\n",
    "    config_class = GPT2Config\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.encoder = GPT2Model(config)\n",
    "        self.second_encoder = GPT2Model(config)\n",
    "        self.decoder = GPT2LMHeadModel(config)\n",
    "\n",
    "    def forward(self, input_ids, labels=None, attention_mask=None):\n",
    "        encoder_outputs = self.encoder(input_ids)\n",
    "        hidden_embedding = encoder_outputs.last_hidden_state[:,-1,:].unsqueeze(1)\n",
    "        # just to obtain the hidden embeddings\n",
    "        with torch.no_grad():\n",
    "            decoder_hidden_inputs = self.second_encoder(input_ids, output_hidden_states=True).hidden_states[0]\n",
    "        #hidden_embedding_dim = hidden_embedding.shape[2]\n",
    "        updated_input = torch.cat((hidden_embedding, decoder_hidden_inputs), dim=1)\n",
    "        logits = self.decoder(inputs_embeds=updated_input)['logits']\n",
    "        logits = F.log_softmax(logits, dim=-1)\n",
    "        shifted_prediction_scores = logits[:, 1:-1, :]\n",
    "        \n",
    "        labels[attention_mask == 0] = -100 \n",
    "        labels = labels[:, 1:]\n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        lm_loss = loss_fct(shifted_prediction_scores.contiguous().view(-1, self.config.vocab_size), labels.contiguous().view(-1))\n",
    "        return {'loss': lm_loss, 'logits':logits[:,1:,:]}\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyModel were not initialized from the model checkpoint at ./model3weights_2024-07-04--16:34:15 and are newly initialized: ['decoder.lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "checkpoint = './model3weights_2024-07-04--16:34:15'\n",
    "model = MyModel.from_pretrained(checkpoint)\n",
    "tokenizer = tokenizer = AutoTokenizer.from_pretrained('google-t5/t5-small')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.1158e-01, -7.1719e-01,  2.4815e+00, -1.7552e-01, -8.0174e-01,\n",
       "        -9.5027e-02, -5.3310e-01, -8.0494e-01,  1.8842e+00,  1.7158e+00,\n",
       "         2.8770e-01, -1.3433e+00, -1.5648e+00,  1.7946e+00,  5.7618e-01,\n",
       "        -2.1223e-01,  9.9359e-01,  2.1210e+00,  6.5841e-01,  1.8674e-01,\n",
       "        -1.1252e+00,  8.2801e-01,  1.3153e+00, -2.2609e+00, -8.5337e-01,\n",
       "        -8.1833e-01,  1.1305e+00, -1.6083e+00, -2.0259e+00,  5.0636e-01,\n",
       "         1.5517e+00, -1.4428e+00,  2.1106e+00, -3.2455e-01, -3.4911e+00,\n",
       "        -8.5512e-01,  1.0983e+00, -5.8201e-01, -8.6580e-01, -1.8299e+00,\n",
       "        -9.5475e-01, -9.0942e-01, -6.6502e-01, -1.4318e+00, -3.7600e-01,\n",
       "        -9.7263e-01, -1.8523e-01, -7.5073e-01, -1.0162e+00, -5.6599e-01,\n",
       "        -8.2322e-01,  1.1130e-02,  2.2469e+00, -6.2895e-01,  2.7641e-02,\n",
       "         2.5279e-01,  8.8550e-01,  1.6353e-01,  4.4655e-01,  3.8632e-01,\n",
       "        -8.5231e-01,  8.2634e-01,  8.0934e-02, -1.3880e+00,  4.0966e-01,\n",
       "        -1.3839e+00, -5.8625e-01,  1.3884e+00, -5.8532e-01,  5.6339e-01,\n",
       "         3.0431e-01,  2.8033e-01, -1.5364e+00, -9.6785e-01,  7.5627e-01,\n",
       "         4.3378e-01,  4.8496e-01,  9.7769e-01,  8.0728e-01, -1.5244e+00,\n",
       "         3.2611e-01, -2.7206e-01,  2.8959e-02, -9.9852e-01, -9.7664e-02,\n",
       "        -1.5058e+00, -3.7486e-01,  1.3402e+00,  2.7195e-01, -6.7207e-01,\n",
       "        -6.3389e-01, -6.4592e-02, -1.0863e+00,  2.0475e+00, -1.5619e+00,\n",
       "         5.1860e-01, -1.7385e-02,  1.5631e+00, -3.0377e+00, -3.0873e+00,\n",
       "         5.3257e-01, -9.5624e-02,  1.3408e+00, -6.3271e-02,  7.7086e-01,\n",
       "         9.9138e-01,  2.3521e+00,  4.5156e-01, -1.3928e+00,  9.3852e-01,\n",
       "        -4.0332e-01, -2.5284e-01,  2.2864e-01, -1.3139e-01,  1.2136e+00,\n",
       "        -2.4209e+00, -6.1060e-01, -2.2195e+00, -8.7888e-01, -1.6413e+00,\n",
       "        -2.3383e+00, -1.9555e-01, -6.0716e-01,  2.7387e-01,  1.2289e+00,\n",
       "         5.3876e-01, -7.3409e-01, -8.3859e-01, -9.7114e-01, -4.5740e-01,\n",
       "        -4.7813e-01,  2.3723e+00, -1.4921e+00,  6.9015e-01, -2.8084e+00,\n",
       "        -3.2890e-01, -1.7928e-01, -3.5036e-01,  1.1553e+00,  7.3851e-01,\n",
       "        -1.0196e-01, -2.1919e+00,  3.3908e-01,  2.1326e-01, -1.6320e+00,\n",
       "        -2.1146e+00,  1.1318e+00, -6.7270e-01, -1.2592e+00,  8.4476e-01,\n",
       "        -1.6799e+00, -3.1055e-01,  7.2523e-01,  9.3981e-01,  1.1991e+00,\n",
       "        -2.2985e+00,  9.7205e-01,  2.3988e-01,  1.1203e+00,  1.2455e+00,\n",
       "        -1.1668e+00, -1.3582e+00, -2.9902e-01, -9.2044e-02, -2.5655e+00,\n",
       "        -7.3636e-01,  2.7098e-01,  1.6631e+00, -6.7459e-01, -6.1408e-01,\n",
       "        -1.7977e+00, -1.6846e+00, -7.8782e-01,  7.2699e-01, -1.2196e+00,\n",
       "        -1.1733e+00, -2.1133e+00,  1.6593e+00, -3.3238e-01,  1.4217e+00,\n",
       "        -2.8335e+00, -8.9733e-01,  1.4904e+00,  1.0949e+00, -2.7227e+00,\n",
       "        -8.3162e-01,  3.4560e-01, -1.1180e-01, -9.7976e-02,  7.2913e-01,\n",
       "         7.1190e-01,  1.2257e+00,  2.4552e+00,  2.0424e+00,  2.7497e+00,\n",
       "         5.5303e-01, -1.6223e+00,  1.6008e+00,  1.1072e+00,  1.1142e-01,\n",
       "        -8.2721e-01,  1.1392e+00, -3.4328e-01, -1.0419e+00,  1.7288e+00,\n",
       "         2.7686e-01, -1.0947e-01, -2.7861e+00, -1.2235e+00,  1.1486e-01,\n",
       "         6.9427e-01,  1.9930e+00, -5.8693e-01, -1.6373e+00, -1.0832e+00,\n",
       "         1.0774e+00, -2.4905e+00,  9.4359e-01, -8.3995e-01,  1.7080e+00,\n",
       "         4.6325e-01,  1.3263e-01, -1.0160e+00,  1.1982e+00, -9.5449e-02,\n",
       "         9.4990e-01, -2.7623e+00, -9.2677e-01, -3.2139e-01,  2.4035e+00,\n",
       "        -2.3220e-02,  1.7435e+00,  9.0964e-01,  2.6523e-01,  2.2477e+00,\n",
       "         3.6494e+00, -9.0096e-01, -1.4030e+00,  4.1182e-01, -1.9976e+00,\n",
       "         4.8971e-01,  6.4503e-01, -5.4512e-01,  1.0560e+00, -1.0513e+00,\n",
       "         1.2474e+00,  1.0529e-01, -3.7338e-01, -6.5350e-02, -1.4026e+00,\n",
       "        -2.8488e-01, -2.2837e-01, -1.6456e+00, -8.7590e-01,  9.6582e-01,\n",
       "         1.6039e+00, -8.2554e-01,  4.8549e+00, -1.1195e+00, -2.8509e-01,\n",
       "        -4.5797e-01, -5.8134e-01,  1.5778e-01, -1.0282e+00,  2.1015e+00,\n",
       "        -8.3269e-01,  5.6069e-01, -2.1143e+00, -2.1122e+00, -7.9003e-02,\n",
       "         1.6500e+00,  1.2449e+00, -1.3756e+00,  5.9991e-01,  8.2620e-01,\n",
       "        -3.8405e-01, -7.6022e-01,  8.9009e-01,  2.1584e-01,  5.2442e-03,\n",
       "        -5.6413e-01,  4.0230e-02,  5.6264e-01, -6.3145e-01,  1.3143e-01,\n",
       "        -5.3033e-01, -5.4684e-01, -1.4396e+00, -1.8661e-02,  1.3021e-01,\n",
       "        -3.8632e-01,  4.0500e-01,  2.3257e-01,  3.7260e-01,  1.1748e+00,\n",
       "         7.2247e-02,  9.7246e-01,  1.3501e+00,  2.7802e+00, -6.4002e-01,\n",
       "         3.8388e-01,  9.9164e-01,  4.7464e-01, -1.3815e+00,  6.9813e-01,\n",
       "        -1.0039e+00,  5.1607e-02,  3.3707e-01,  9.0505e-01,  6.5962e-01,\n",
       "        -6.2363e-01, -1.4737e+00, -1.0781e+00, -6.2716e-01, -6.3507e-01,\n",
       "         5.6393e-01,  6.2026e-01,  5.8090e-01, -2.0547e-01, -1.6420e+00,\n",
       "        -2.5106e-01, -8.0452e-01,  2.9318e+00,  6.1027e-01,  1.2046e-01,\n",
       "         6.0488e-02,  3.7313e+00, -1.5084e+00, -2.4274e+00,  1.6314e+00,\n",
       "        -8.5307e-02, -2.3256e+00, -7.2245e-01,  3.3954e+00, -4.4561e-01,\n",
       "         5.9082e-01,  1.7882e+00, -1.4128e-01,  1.0434e+00, -6.5264e-01,\n",
       "        -7.3279e-02, -3.6346e-01,  1.6257e-01, -2.3686e-01,  1.3521e+00,\n",
       "        -1.4632e-02,  9.9375e-01,  1.4538e+00,  4.8440e-01,  4.3706e-01,\n",
       "        -2.0606e-01,  1.8820e+00, -6.0244e-01, -1.7922e-01, -1.2103e+00,\n",
       "        -1.8781e-01, -2.3360e-01,  1.1315e-01,  1.3803e+00, -4.3638e-01,\n",
       "        -2.6134e+00,  2.2317e+00,  4.3535e+00, -3.2759e+00, -9.4842e-01,\n",
       "        -8.0220e-01,  1.5399e+00, -4.2650e-01,  4.0163e-01, -2.4450e+00,\n",
       "         2.1389e+00, -6.0213e-01,  1.7106e+00,  9.0783e-01,  9.0395e-03,\n",
       "         4.5177e-01,  5.0331e-02,  1.8459e+00,  5.1921e-01,  7.6386e-01,\n",
       "        -1.3526e+00,  9.6504e-01,  5.7077e-01,  6.7288e-01,  3.1176e-01,\n",
       "         1.0686e+00, -8.3240e-01,  1.0050e+00,  9.2535e-01, -8.2519e-01,\n",
       "         9.8843e-01,  7.7545e-01,  2.5451e+00, -1.8255e-01,  6.1372e-02,\n",
       "        -8.8695e-01,  2.2426e+00,  2.7452e+00,  1.6106e+00,  6.6713e-01,\n",
       "         3.4979e-01,  9.7194e-01, -1.2699e+00, -1.0836e+00,  2.0119e+00,\n",
       "         1.4621e+00, -2.8660e+00, -4.9765e-02, -4.1213e-01,  6.6072e-01,\n",
       "        -7.4814e-01,  6.3473e-01, -8.4735e-01, -2.6686e+00, -3.4480e-01,\n",
       "        -2.2091e-01, -4.4719e-01, -8.3233e-01, -1.5729e+00, -3.2561e-01,\n",
       "        -7.8128e-02, -3.6230e-01,  8.9713e-01, -1.1478e+00, -1.8855e-01,\n",
       "        -1.0200e+00,  9.3246e-02,  4.1108e+00,  1.4752e+00,  3.2704e-01,\n",
       "        -9.0353e-01, -5.6295e-01,  6.9793e-01,  1.2304e-01,  1.8807e+00,\n",
       "         1.3289e-01,  2.0331e-01,  3.4646e-01,  5.1747e-02, -9.3294e-01,\n",
       "         1.4795e+00, -2.0117e+00,  1.8949e-01, -1.9625e+00,  1.4162e+00,\n",
       "         6.2785e-01,  1.0944e+00,  1.2051e+00,  7.2951e-01,  4.6271e-01,\n",
       "         8.3115e-02,  5.8285e-01, -7.6016e-01,  8.3150e-01, -8.0946e-01,\n",
       "        -4.5219e-02, -2.1147e+00,  2.0489e+00,  1.8248e+00,  5.8356e-01,\n",
       "        -1.8484e-01, -1.2338e+00,  2.5919e+00, -2.5883e+00, -6.3563e-01,\n",
       "        -4.3836e+00, -4.8338e-01,  9.2733e-02, -3.7495e-01,  4.0410e-02,\n",
       "         7.7224e-01,  1.3125e+00, -1.1918e+00,  6.5674e-01,  7.9703e-01,\n",
       "         3.2905e-01,  5.4690e-01,  2.1065e+00, -1.3591e+00, -2.2001e+00,\n",
       "        -2.4610e+00,  8.5450e-02, -1.4393e-01, -2.2733e+00,  2.0593e-01,\n",
       "         1.4364e+00, -9.6940e-02,  2.2609e-01, -2.4140e-01, -1.4280e-01,\n",
       "        -7.1727e-01,  2.6762e-01, -1.7666e+00, -1.8019e-01,  7.4993e-01,\n",
       "         1.9674e+00, -1.0167e-01,  8.1732e-01, -1.6771e+00,  1.3057e+00,\n",
       "         6.0989e-01, -1.6951e-01,  1.3083e+00, -1.1693e+00,  1.5809e+00,\n",
       "        -1.0089e+00, -1.7547e+00,  1.0511e-01,  2.6952e-01,  4.6664e-01,\n",
       "         4.6724e-01, -4.8401e-01,  1.3479e+00, -2.5758e-01,  3.1918e-01,\n",
       "         1.1603e+00,  4.3061e-01, -2.4938e-02, -2.2147e+00,  3.2522e-01,\n",
       "         3.0267e-01,  3.2206e-01, -1.5491e-01, -1.3137e+00,  3.9795e-01,\n",
       "         9.5228e-01, -7.8413e-01, -5.9450e-01, -5.5237e-01, -2.0060e+00,\n",
       "        -1.1942e+00,  1.4116e-01, -1.1235e+00,  1.0408e+00, -4.0840e-01,\n",
       "        -6.1242e-01, -1.0599e+00, -6.0078e-01,  2.0999e-01, -3.6592e+00,\n",
       "        -1.7601e+00, -2.6459e+00, -3.2063e-01,  9.4465e-01,  2.5485e-01,\n",
       "        -1.1804e+00,  2.8687e+00,  7.6002e-01,  1.4260e-01,  7.9296e-01,\n",
       "         2.6793e+00, -1.0596e-01, -6.6233e-01, -1.2934e+00, -1.4951e+00,\n",
       "        -2.1204e+00, -7.6738e-02, -7.7767e-01,  8.7791e-02,  1.4951e+00,\n",
       "         2.1420e-02,  9.4436e-01,  3.1026e-01, -9.4222e-01,  2.2243e+00,\n",
       "        -2.6567e+00,  8.9337e-01,  1.2077e-01, -1.3165e+00, -1.5599e+00,\n",
       "        -6.0636e-02,  3.2183e+00, -1.2429e-02,  3.1495e-01,  1.7797e-01,\n",
       "         1.1408e+00, -1.0976e+00,  2.6578e+00, -6.5183e-01,  3.0567e-01,\n",
       "         1.6034e-01,  2.5714e+00,  2.5563e+00, -2.3290e-01,  1.7312e-02,\n",
       "        -5.1285e-01,  2.2418e-01, -1.2470e+00,  1.2090e+00, -1.0812e+00,\n",
       "         3.6405e+00, -1.3227e+00, -2.8902e-01, -1.8491e+00,  1.7547e+00,\n",
       "         1.1411e+00, -1.3809e+00,  9.0938e-01,  2.0798e+00,  1.1485e+00,\n",
       "        -2.9865e+00, -8.6338e-01,  8.0275e-01, -1.1675e+00, -4.1146e-01,\n",
       "        -2.5686e+00,  2.0063e+00, -5.5707e-01, -8.8443e-01,  1.0730e+00,\n",
       "        -6.9839e-01,  7.8129e-01, -4.0569e-01, -9.4466e-01,  2.4075e-01,\n",
       "         6.3077e-01,  1.6253e+00, -1.9627e-02, -7.9420e-01,  1.4784e-01,\n",
       "         1.3097e+00,  2.1562e+00,  4.7369e-01,  1.8818e+00, -1.4290e+00,\n",
       "         3.5527e-02, -1.0043e+00,  6.8143e-01,  1.4614e+00, -1.2325e+00,\n",
       "         1.8857e+00,  1.9810e+00,  3.5197e-01, -4.3125e-01,  9.2210e-02,\n",
       "         2.1972e-01, -1.5434e+00,  4.6449e-01, -8.3798e-01, -3.4161e-01,\n",
       "        -6.9320e-02, -3.4929e-01, -7.3910e-01,  3.1803e-01, -1.2741e-01,\n",
       "        -1.6439e+00,  1.8440e-01,  8.8660e-01, -2.3813e+00,  2.2241e+00,\n",
       "        -1.4706e-03, -1.9403e+00, -3.8030e-01, -4.8674e-01,  7.9655e-01,\n",
       "        -8.5446e-01,  8.5856e-01,  7.9634e-01, -9.2811e-02, -2.9184e-02,\n",
       "        -9.2470e-02, -1.4034e+00,  3.9461e-02, -1.3955e-01, -1.6789e+00,\n",
       "         1.8381e+00,  9.6578e-01, -6.1253e-01, -2.3945e-01,  2.2201e+00,\n",
       "         4.0169e-01,  6.5248e-01, -1.2197e+00,  2.3532e+00,  2.7059e-01,\n",
       "        -4.3167e-02,  6.0163e-01, -7.0989e-02, -2.7763e-01,  4.4032e-01,\n",
       "        -1.0026e+00,  1.2968e+00,  2.1631e+00,  1.0854e+00,  1.3714e-01,\n",
       "        -1.3864e+00, -6.9093e-01,  7.6776e-01, -1.5743e-01, -1.7272e+00,\n",
       "        -4.3605e-01, -7.7433e-02,  2.2607e-01, -8.5447e-02,  1.1198e+00,\n",
       "        -1.0219e+00, -1.2975e+00, -3.0380e-01,  1.2348e+00, -2.0063e-01,\n",
       "         3.8291e-01,  5.7780e-01, -2.0783e-02,  1.2255e+00,  1.7435e+00,\n",
       "         2.1253e-01,  4.6091e-01, -7.8621e-01,  1.4620e+00,  9.4148e-01,\n",
       "        -2.0752e+00,  2.7341e-01,  1.1982e+00, -8.8593e-01,  3.7823e-01,\n",
       "        -7.6517e-01, -5.4998e-01,  5.6218e-01,  3.6186e-01, -1.1453e+00,\n",
       "         1.8647e+00,  2.3434e+00,  5.1101e-02, -1.3810e-01,  3.3601e-01,\n",
       "        -2.0282e-01,  1.2350e+00, -3.8778e-01,  1.5718e+00,  2.1673e-01,\n",
       "         8.4428e-01,  2.3308e+00, -5.6564e-01, -1.4399e+00,  7.1829e-01,\n",
       "        -8.6100e-01,  1.8844e-01,  1.3086e+00, -1.9953e+00,  2.0973e+00,\n",
       "         1.3262e+00, -1.3318e+00, -1.7718e+00, -1.7438e+00,  1.3626e-01,\n",
       "         8.0875e-01, -7.2263e-01,  1.0831e+00,  9.2248e-01,  4.6180e-01,\n",
       "         1.4437e+00, -2.6205e+00, -3.6785e-01, -1.0661e+00,  5.8665e-01,\n",
       "        -1.9031e+00,  4.0023e-01, -1.6979e-01, -4.9914e+00, -2.2683e+00,\n",
       "        -2.6532e-01,  5.0668e-01,  2.4652e+00, -2.5872e+00, -4.2439e-01,\n",
       "        -7.1591e-01, -1.0149e+00, -2.0901e+00], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "input_ids1 = tokenizer('Hi I am a student!', return_tensors='pt')\n",
    "input_ids2 = tokenizer('Hi I am a professor!', return_tensors='pt')\n",
    "hidden_embedding1 = model.encoder(**input_ids1).last_hidden_state[0,-1,:]\n",
    "hidden_embedding2 = model.encoder(**input_ids2).last_hidden_state[0,-1,:]\n",
    "print('norm is ', torch.norm(input_ids1 - input_ids2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
